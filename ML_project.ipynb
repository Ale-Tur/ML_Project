{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Loading Dataset\n",
    "dataframe = pd.read_csv('updated_pollution_dataset.csv')\n",
    "\n",
    "#Checking for NaN value\n",
    "print(dataframe.isnull().values.any())\n",
    "\n",
    "#Checking for unique values\n",
    "unique_class = dataframe['Air Quality'].unique()\n",
    "\n",
    "df_row = np.size(dataframe,0)\n",
    "df_col = np.size(dataframe,1)\n",
    "\n",
    "#Getting class index\n",
    "index_good = dataframe[dataframe['Air Quality'] == 'Good'].index\n",
    "index_moderate = dataframe[dataframe['Air Quality'] == 'Moderate'].index\n",
    "index_poor = dataframe[dataframe['Air Quality'] == 'Poor'].index\n",
    "index_hazard = dataframe[dataframe['Air Quality'] == 'Hazardous'].index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset: 98%-99% internal - 1%-2% external.\n",
    "This dataset wil be completly external just to see final results (like dataset given at the end of competition to test models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indetifing indices for external dataset\n",
    "#This is done in one section just so every run of the program does not generate new datasets\n",
    "external_size_good = math.floor(0.01*np.size(index_good))\n",
    "external_size_moderate = math.floor(0.01*np.size(index_moderate))\n",
    "external_size_poor = math.floor(0.01*np.size(index_poor))\n",
    "external_size_hazard = math.floor(0.02*np.size(index_hazard))\n",
    "\n",
    "#Extracting indices for external dataset\n",
    "index_untouch_good = np.zeros(external_size_good)\n",
    "i = 0\n",
    "while index_untouch_good[external_size_good-1,] == 0:\n",
    "    r = int(random.choice(index_good))\n",
    "    if r not in index_untouch_good:\n",
    "        index_untouch_good[i] = r\n",
    "        i = i + 1\n",
    "\n",
    "index_untouch_moderate = np.zeros(external_size_moderate)\n",
    "i = 0\n",
    "while index_untouch_moderate[external_size_moderate-1,] == 0:\n",
    "    r = int(random.choice(index_moderate))\n",
    "    if r not in index_untouch_moderate:\n",
    "        index_untouch_moderate[i] = r\n",
    "        i = i + 1\n",
    "\n",
    "index_untouch_poor = np.zeros(external_size_poor)\n",
    "i = 0\n",
    "while index_untouch_poor[external_size_poor-1,] == 0:\n",
    "    r = int(random.choice(index_poor))\n",
    "    if r not in index_untouch_poor:\n",
    "        index_untouch_poor[i] = r\n",
    "        i = i + 1\n",
    "\n",
    "index_untouch_hazard = np.zeros(external_size_hazard)\n",
    "i = 0\n",
    "while index_untouch_hazard[external_size_hazard-1,] == 0:\n",
    "    r = int(random.choice(index_hazard))\n",
    "    if r not in index_untouch_hazard:\n",
    "        index_untouch_hazard[i] = r\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the external dataset\n",
    "df_untouch_good = dataframe.iloc[index_untouch_good]\n",
    "df_untouch_moderate = dataframe.iloc[index_untouch_moderate]\n",
    "df_untouch_poor = dataframe.iloc[index_untouch_poor]\n",
    "df_untouch_hazard = dataframe.iloc[index_untouch_hazard]\n",
    "df_untouch = pd.concat([df_untouch_good,df_untouch_hazard,df_untouch_moderate,df_untouch_poor])\n",
    "\n",
    "#Removing indices for external (maybe don't needed, check next time)\n",
    "for i in range(0,external_size_good):\n",
    "    index = np.argwhere(index_good == index_untouch_good[i])\n",
    "    index_good = np.delete(index_good,index)\n",
    "\n",
    "for i in range(0,external_size_moderate):\n",
    "    index = np.argwhere(index_moderate == index_untouch_moderate[i])\n",
    "    index_moderate = np.delete(index_moderate,index)\n",
    "\n",
    "for i in range(0,external_size_poor):\n",
    "    index = np.argwhere(index_poor == index_untouch_poor[i])\n",
    "    index_poor = np.delete(index_poor, index)\n",
    "\n",
    "for i in range(0,external_size_hazard):\n",
    "    index = np.argwhere(index_hazard == index_untouch_hazard[i])\n",
    "    index_hazard = np.delete(index_hazard,index)\n",
    "\n",
    "del index,i\n",
    "del index_untouch_good,index_untouch_hazard,index_untouch_moderate,index_untouch_poor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train and test set (20% of each class goes into test, maybe change after first results)\n",
    "test_size_good = round(0.2*np.size(index_good))\n",
    "test_size_poor = round(0.2*np.size(index_poor))\n",
    "test_size_moderate = round(0.2*np.size(index_moderate))\n",
    "test_size_hazard = round(0.2*np.size(index_hazard))\n",
    "\n",
    "#Getting indices for test set (probably this could have been a function, also for above block)\n",
    "index_test_good = np.zeros(test_size_good)\n",
    "i = 0\n",
    "while index_test_good[test_size_good-1,] == 0:\n",
    "    r = int(random.choice(index_good))\n",
    "    if r not in index_test_good:\n",
    "        index_test_good[i] = r\n",
    "        i = i + 1\n",
    "\n",
    "index_test_moderate = np.zeros(test_size_moderate)\n",
    "i = 0\n",
    "while index_test_moderate[test_size_moderate-1,] == 0:\n",
    "    r = int(random.choice(index_moderate))\n",
    "    if r not in index_test_moderate:\n",
    "        index_test_moderate[i] = r\n",
    "        i = i + 1\n",
    "\n",
    "index_test_poor = np.zeros(test_size_poor)\n",
    "i = 0\n",
    "while index_test_poor[test_size_poor-1,] == 0:\n",
    "    r = int(random.choice(index_poor))\n",
    "    if r not in index_test_poor:\n",
    "        index_test_poor[i] = r\n",
    "        i = i + 1\n",
    "\n",
    "index_test_hazard = np.zeros(test_size_hazard)\n",
    "i = 0\n",
    "while index_test_hazard[test_size_hazard-1,] == 0:\n",
    "    r = int(random.choice(index_hazard))\n",
    "    if r not in index_test_hazard:\n",
    "        index_test_hazard[i] = r\n",
    "        i = i + 1\n",
    "\n",
    "#Creating the test dataset\n",
    "df_test_good = dataframe.iloc[index_test_good]\n",
    "df_test_moderate = dataframe.iloc[index_test_moderate]\n",
    "df_test_poor = dataframe.iloc[index_test_poor]\n",
    "df_test_hazard = dataframe.iloc[index_test_hazard]\n",
    "df_test = pd.concat([df_test_good,df_test_hazard,df_test_moderate,df_test_poor])\n",
    "\n",
    "#del index_test_good,index_test_hazard,index_test_moderate,index_test_poor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
